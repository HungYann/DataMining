{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WQD7005 - Data Mining\n",
    "\n",
    "\n",
    "### Lab 3\n",
    "\n",
    "\n",
    "##### Matrix Number : 17201091/1\n",
    "    \n",
    "##### Name : LIU,HONGYANG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.Prequisite\n",
    "\n",
    "Perform the following steps before trying the exercises:\n",
    "\n",
    "a) Import pandas as \"pd\" and load the lab1 dataset into \"df\".\n",
    "\n",
    "\n",
    "b) Print dataset information to refresh your memory.\n",
    "\n",
    "\n",
    "c) Run preprocess_data function on the dataframe to perform preprocessing steps \n",
    "discussed last week.\n",
    "\n",
    "\n",
    "d) Split your data into training and test with 70:30 distribution, stratified, random state 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TargetB</th>\n",
       "      <th>ID</th>\n",
       "      <th>TargetD</th>\n",
       "      <th>GiftCnt36</th>\n",
       "      <th>GiftCntAll</th>\n",
       "      <th>GiftCntCard36</th>\n",
       "      <th>GiftCntCardAll</th>\n",
       "      <th>GiftAvgLast</th>\n",
       "      <th>GiftAvg36</th>\n",
       "      <th>GiftAvgAll</th>\n",
       "      <th>...</th>\n",
       "      <th>PromCntCardAll</th>\n",
       "      <th>StatusCat96NK</th>\n",
       "      <th>StatusCatStarAll</th>\n",
       "      <th>DemCluster</th>\n",
       "      <th>DemAge</th>\n",
       "      <th>DemGender</th>\n",
       "      <th>DemHomeOwner</th>\n",
       "      <th>DemMedHomeValue</th>\n",
       "      <th>DemPctVeterans</th>\n",
       "      <th>DemMedIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>9.25</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.88</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>67.0</td>\n",
       "      <td>F</td>\n",
       "      <td>U</td>\n",
       "      <td>186800</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.17</td>\n",
       "      <td>3.73</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>87600</td>\n",
       "      <td>36</td>\n",
       "      <td>38750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>185937</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>139200</td>\n",
       "      <td>27</td>\n",
       "      <td>38942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>29637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>53.0</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>168100</td>\n",
       "      <td>37</td>\n",
       "      <td>71509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TargetB      ID  TargetD  GiftCnt36  GiftCntAll  GiftCntCard36  \\\n",
       "0        0   14974      NaN          2           4              1   \n",
       "1        0    6294      NaN          1           8              0   \n",
       "2        1   46110      4.0          6          41              3   \n",
       "3        1  185937     10.0          3          12              3   \n",
       "4        0   29637      NaN          1           1              1   \n",
       "\n",
       "   GiftCntCardAll  GiftAvgLast  GiftAvg36  GiftAvgAll  ...  PromCntCardAll  \\\n",
       "0               3         17.0      13.50        9.25  ...              13   \n",
       "1               3         20.0      20.00       15.88  ...              24   \n",
       "2              20          6.0       5.17        3.73  ...              22   \n",
       "3               8         10.0       8.67        8.50  ...              16   \n",
       "4               1         20.0      20.00       20.00  ...               6   \n",
       "\n",
       "   StatusCat96NK  StatusCatStarAll  DemCluster  DemAge  DemGender  \\\n",
       "0              A                 0           0     NaN          F   \n",
       "1              A                 0          23    67.0          F   \n",
       "2              S                 1           0     NaN          M   \n",
       "3              E                 1           0     NaN          M   \n",
       "4              F                 0          35    53.0          M   \n",
       "\n",
       "   DemHomeOwner  DemMedHomeValue  DemPctVeterans DemMedIncome  \n",
       "0             U                0               0            0  \n",
       "1             U           186800              85            0  \n",
       "2             U            87600              36        38750  \n",
       "3             U           139200              27        38942  \n",
       "4             U           168100              37        71509  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "df = pd.read_csv(\"lab1.csv\");\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9686 entries, 0 to 9685\n",
      "Data columns (total 28 columns):\n",
      "TargetB             9686 non-null int64\n",
      "ID                  9686 non-null int64\n",
      "TargetD             4843 non-null float64\n",
      "GiftCnt36           9686 non-null int64\n",
      "GiftCntAll          9686 non-null int64\n",
      "GiftCntCard36       9686 non-null int64\n",
      "GiftCntCardAll      9686 non-null int64\n",
      "GiftAvgLast         9686 non-null float64\n",
      "GiftAvg36           9686 non-null float64\n",
      "GiftAvgAll          9686 non-null float64\n",
      "GiftAvgCard36       7906 non-null float64\n",
      "GiftTimeLast        9686 non-null int64\n",
      "GiftTimeFirst       9686 non-null int64\n",
      "PromCnt12           9686 non-null int64\n",
      "PromCnt36           9686 non-null int64\n",
      "PromCntAll          9686 non-null int64\n",
      "PromCntCard12       9686 non-null int64\n",
      "PromCntCard36       9686 non-null int64\n",
      "PromCntCardAll      9686 non-null int64\n",
      "StatusCat96NK       9686 non-null object\n",
      "StatusCatStarAll    9686 non-null int64\n",
      "DemCluster          9686 non-null int64\n",
      "DemAge              7279 non-null float64\n",
      "DemGender           9686 non-null object\n",
      "DemHomeOwner        9686 non-null object\n",
      "DemMedHomeValue     9686 non-null int64\n",
      "DemPctVeterans      9686 non-null int64\n",
      "DemMedIncome        9686 non-null int64\n",
      "dtypes: float64(6), int64(19), object(3)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "def preprocess_data(df):\n",
    "    \n",
    "    # Setting correct type to variables\n",
    "    df['DemCluster'] = df['DemCluster'].astype(str)\n",
    "\n",
    "    #DemHomeOwner should be a binary variable\n",
    "\n",
    "    df['DemHomeOwner'] = df['DemHomeOwner'].replace({'H':1,'U':0})\n",
    "\n",
    "\n",
    "    #denote errorneous values in DemMidIncome\n",
    "\n",
    "    mask = df['DemMedIncome'] < 1\n",
    "    df.loc[mask, 'DemMedIncome'] = np.nan\n",
    "    \n",
    "    #use the median value to relpace 0 vlaue\n",
    "    df['DemMedIncome'] = df['DemMedIncome'].replace({0:df['DemMedIncome'].median()})\n",
    "    df['DemAge'] = df['DemAge'].fillna({0:df['DemAge'].median()})\n",
    "\n",
    "        \n",
    "    df['DemAge'].fillna(df['DemAge'].median(), inplace=True)\n",
    "    df['DemMedIncome'].fillna(df['DemMedIncome'].median(), inplace = True)\n",
    "    df['GiftAvgCard36'].fillna(df['GiftAvgCard36'].median(), inplace = True)\n",
    "    \n",
    "    \n",
    "    #delete columns\n",
    "    df = df.drop(['ID'], axis=1)\n",
    "    df = df.drop(['TargetD'], axis=1)\n",
    "    \n",
    "    #Formatting Categorical Variable\n",
    "    \n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TargetB</th>\n",
       "      <th>GiftCnt36</th>\n",
       "      <th>GiftCntAll</th>\n",
       "      <th>GiftCntCard36</th>\n",
       "      <th>GiftCntCardAll</th>\n",
       "      <th>GiftAvgLast</th>\n",
       "      <th>GiftAvg36</th>\n",
       "      <th>GiftAvgAll</th>\n",
       "      <th>GiftAvgCard36</th>\n",
       "      <th>GiftTimeLast</th>\n",
       "      <th>...</th>\n",
       "      <th>DemCluster_51</th>\n",
       "      <th>DemCluster_52</th>\n",
       "      <th>DemCluster_53</th>\n",
       "      <th>DemCluster_6</th>\n",
       "      <th>DemCluster_7</th>\n",
       "      <th>DemCluster_8</th>\n",
       "      <th>DemCluster_9</th>\n",
       "      <th>DemGender_F</th>\n",
       "      <th>DemGender_M</th>\n",
       "      <th>DemGender_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>9.25</td>\n",
       "      <td>17.00</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.88</td>\n",
       "      <td>12.50</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.17</td>\n",
       "      <td>3.73</td>\n",
       "      <td>5.00</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.67</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.67</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TargetB  GiftCnt36  GiftCntAll  GiftCntCard36  GiftCntCardAll  GiftAvgLast  \\\n",
       "0        0          2           4              1               3         17.0   \n",
       "1        0          1           8              0               3         20.0   \n",
       "2        1          6          41              3              20          6.0   \n",
       "3        1          3          12              3               8         10.0   \n",
       "4        0          1           1              1               1         20.0   \n",
       "\n",
       "   GiftAvg36  GiftAvgAll  GiftAvgCard36  GiftTimeLast  ...  DemCluster_51  \\\n",
       "0      13.50        9.25          17.00            21  ...              0   \n",
       "1      20.00       15.88          12.50            26  ...              0   \n",
       "2       5.17        3.73           5.00            18  ...              0   \n",
       "3       8.67        8.50           8.67             9  ...              0   \n",
       "4      20.00       20.00          20.00            21  ...              0   \n",
       "\n",
       "   DemCluster_52  DemCluster_53  DemCluster_6  DemCluster_7  DemCluster_8  \\\n",
       "0              0              0             0             0             0   \n",
       "1              0              0             0             0             0   \n",
       "2              0              0             0             0             0   \n",
       "3              0              0             0             0             0   \n",
       "4              0              0             0             0             0   \n",
       "\n",
       "   DemCluster_9  DemGender_F  DemGender_M  DemGender_U  \n",
       "0             0            1            0            0  \n",
       "1             0            1            0            0  \n",
       "2             0            0            1            0  \n",
       "3             0            0            1            0  \n",
       "4             0            0            1            0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load data\n",
    "\n",
    "#Traing dataset\n",
    "X=df.drop(['TargetB'],axis=1)\n",
    "\n",
    "#Target dataset\n",
    "Y=df['TargetB']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,stratify=Y,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Standardisation and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform following operations and answer the following questions:**\n",
    "\n",
    "a) What is the difference between logistic regression and linear regression?  \n",
    "\n",
    "- In case of Linear Regression the outcome is continuous while in case of Logistic Regression outcome is discrete (not continuous).\n",
    "\n",
    "- Linear Regression is a regression algorithm for Machine Learning while Logistic Regression is a classification Algorithm for machine learning.\n",
    "\n",
    "___\n",
    "\n",
    "b) Describe how logistic regression perform its prediction. \n",
    "\n",
    "- logistic regression could transform the input data into binary class.\n",
    "\n",
    "___\n",
    "c) Write code to perform standardisation on your training and test dataset. \n",
    "\n",
    "see code \n",
    "\n",
    "___\n",
    "\n",
    "d) What does standardisation do to your data? How does it benefit your regression model? \n",
    "\n",
    "\n",
    "Scaling and standardizing can help features arrive in more digestible form for algorithms. It could help scaling input features so they have mean of 0 and standard deviation of 1. \n",
    "\n",
    "In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "In addition, standardised input features allow us to compare their regression weights and figure out the important variables.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "e) Write code to fit a logistic regression model to your training data. How does it perform on the training and test data? Do you see any indication of overfitting?  \n",
    "\n",
    "**explanation:**\n",
    "\n",
    "Overfitting means the model fit well in the training datasets, but badly in test datasets\n",
    "\n",
    "So we only need to compare the performance of the model on training and testing datasets.\n",
    "\n",
    "If there is no big difference.\n",
    "\n",
    "The model is not overfitting, vice versa.\n",
    "\n",
    "Consequently, the not much indication of overfitting.\n",
    "\n",
    "see code \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "f) Write code to find the most important features in your model.\n",
    "\n",
    "see code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59      1453\n",
      "           1       0.59      0.57      0.58      1453\n",
      "\n",
      "    accuracy                           0.58      2906\n",
      "   macro avg       0.58      0.58      0.58      2906\n",
      "weighted avg       0.58      0.58      0.58      2906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import logistic regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logisticRegression = LogisticRegression()\n",
    "\n",
    " # fit \n",
    "logisticRegression.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logisticRegression.predict(X_test)\n",
    "\n",
    "#performance\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58      1453\n",
      "           1       0.58      0.57      0.57      1453\n",
      "\n",
      "    accuracy                           0.57      2906\n",
      "   macro avg       0.57      0.57      0.57      2906\n",
      "weighted avg       0.57      0.57      0.57      2906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    " # fit \n",
    "logisticRegression.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logisticRegression.predict(X_test)\n",
    "\n",
    "\n",
    "#performance\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "f1_score=metrics.f1_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "\n",
    "objects = (\"accuracy\",\"precision\",\"recall\",\"f1-score\")\n",
    "y_pos = np.arange(len(objects))\n",
    "performance3 = [accuracy,precision,recall,f1_score]\n",
    "\n",
    "plt.bar(y_pos, performance3, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('value')\n",
    "plt.title('preformacne report')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overfitting or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5834808259587021\n",
      "Test accuracy: 0.5746730901582932\n"
     ]
    }
   ],
   "source": [
    "# test the best model\n",
    "print(\"Train accuracy:\", logisticRegression.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", logisticRegression.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting means the model fit well in the training datasets, but badly in test datasets\n",
    "\n",
    "So we only need to compare the performance of the model on training and testing datasets.\n",
    "\n",
    "If there is no big difference.\n",
    "\n",
    "The model is not overfitting, vice versa.\n",
    "\n",
    "Consequently, the not much indication of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5821533923303834\n",
      "Test accuracy: 0.5832759807295251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59      1453\n",
      "           1       0.59      0.57      0.58      1453\n",
      "\n",
      "    accuracy                           0.58      2906\n",
      "   macro avg       0.58      0.58      0.58      2906\n",
      "weighted avg       0.58      0.58      0.58      2906\n",
      "\n",
      "{'C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "\n",
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "# use all cores to tune logistic regression with C parameter\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=0), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GiftTimeLast : -0.10398379814905222\n",
      "GiftCntCard36 : 0.06485233398730723\n",
      "GiftCnt36 : 0.05853084359831786\n",
      "DemMedHomeValue : 0.0571625581037534\n",
      "PromCntCard36 : 0.045115630837314555\n",
      "StatusCat96NK_E : 0.04291701799947188\n",
      "StatusCatStarAll : 0.03805473352502127\n",
      "DemCluster_44 : -0.03721419598180589\n",
      "DemCluster_0 : 0.035040210449018644\n",
      "DemCluster_10 : -0.03499692670703686\n",
      "DemCluster_30 : -0.03223317076474372\n",
      "DemCluster_32 : -0.03089576072366439\n",
      "GiftTimeFirst : 0.030807974556374036\n",
      "DemCluster_40 : 0.02937932607268234\n",
      "DemCluster_16 : -0.028627838133722834\n",
      "DemCluster_23 : 0.027806110502039832\n",
      "GiftAvgLast : -0.02643596312760835\n",
      "DemCluster_3 : 0.025325284704550585\n",
      "DemCluster_47 : -0.024768103728447715\n",
      "DemCluster_15 : -0.022409649202684706\n"
     ]
    }
   ],
   "source": [
    "# most important features\n",
    "import numpy as np\n",
    "\n",
    "coef = cv.best_estimator_.coef_[0]\n",
    "feature_names = X.columns\n",
    "\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "# limit to 20 features, you can leave this out to print out everything\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, GiftTimeLast, GiftCntCard36 and GiftCnt36 are the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
